{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This jupyter notebook replicates the results from Figure 4 in the ISMRM abstract \"Extending Scan-specific Artifact reduction in K-space (SPARK) to advanced encoding and reconstruction schemes\" (Yamin Arefeen et. al.).  In particular, this notebook performs simulation experiments comparing generalized SENSE based reconstructions of wave and non-wave encoded data with SPARK based corrections.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import warnings\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import scipy as sp\n",
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "from bart import bart\n",
    "from utils import cfl\n",
    "from utils import signalprocessing as sig\n",
    "from utils import models\n",
    "from utils import iterative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the dataset and selecting the slices that I want to alias and reconstruct "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Load the fully sampled, multi-channel kspace dataset and normalize \n",
    "allkspace = np.transpose(cfl.readcfl('data/kspaceFullFig2'),(3,2,0,1))\n",
    "allkspace = allkspace / np.max(abs(allkspace.ravel())) * 100  \n",
    "\n",
    "[C,P,M,N] = allkspace.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Parameters for the sms acquisition\n",
    "beginningSliceIndex = 20                     #slice at which we want to \"start\" sms acquisition\n",
    "numslices           = 5                      #multi-band factor, number of slices we simultaneously excite\n",
    "slicedistance       = P // numslices         #distance between slices in z index \n",
    "fovshift            = 3                      #FOV shift factor in the spirit of 'blippied' caipi\n",
    "\n",
    "#-acquisition parameters \n",
    "Ry                  = 2                      #in-plane acceleration factor\n",
    "snr                 = 150                    #noise-level to add to the experiments\n",
    "\n",
    "#-Iterative method parameters\n",
    "senseIterations = 20\n",
    "cudaflag        = 1\n",
    "\n",
    "#-ACS sizes for SPARK parameters.  Acs size in readout direction(x) is M * numslices since will be using \n",
    "#-readout concatenation to modle sms\n",
    "acsx = M * numslices                    \n",
    "acsy = 24\n",
    "\n",
    "#-Learning parameters for the SPARK models we will be training \n",
    "learningRate      = .0075\n",
    "sparkIterations   = 200\n",
    "normalizationflag = 1\n",
    "\n",
    "slices = np.linspace(beginningSliceIndex,beginningSliceIndex + slicedistance * (numslices-1),numslices).astype(int)\n",
    "\n",
    "#-Take fft along 'slice dimension and select kspace of just the slices we care about\n",
    "allkspaceslices = sig.fft(allkspace,-3)\n",
    "kspaceslices = allkspaceslices[:,slices,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Viewing the slices that will be used to model sms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig.mosaic(sig.nor(sig.rsos(sig.ifft2c(kspaceslices),-4)),1,numslices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callibrate the coil sensitivity maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coilslices = np.zeros((C,numslices,M,N),dtype = complex)\n",
    "\n",
    "for ss in range(0,numslices):\n",
    "    print('Callibrating coils for slice %d/%d' % (ss + 1,numslices))\n",
    "    curksp  = np.expand_dims(np.transpose(kspaceslices[:,ss,:,:],axes = (1,2,0)),2)\n",
    "    coilslices[:,ss,:,:] = np.squeeze(np.transpose(bart(1,'ecalib -m 1',curksp),(3,2,0,1)))\n",
    "print('done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shifting the slices/sensitivities and concat along the readout direction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Define the shift amounts\n",
    "if(fovshift > 0):\n",
    "    shifts = np.round(np.linspace(-(numslices / 2 - 1),numslices/2,numslices) * N / fovshift ).astype(int)\n",
    "else:\n",
    "    shifts = np.zeros((numslices)).astype(int)\n",
    "\n",
    "#-Define the function which performs the shifting\n",
    "def performshift(x,shift,direction = 1):\n",
    "    out = np.zeros(x.shape,dtype=complex)\n",
    "    \n",
    "    for ss in range(0,out.shape[-3]):\n",
    "        out[:,ss,:,:] = np.roll(x[:,ss,:,:],direction*shift[ss])\n",
    "    return out\n",
    "      \n",
    "#-Compute shifted slices in image space (as well as the shifted coils)\n",
    "slicesShiftedCoils = performshift(sig.ifft2c(kspaceslices),shifts)\n",
    "shiftedCoils       = performshift(coilslices,shifts)\n",
    "\n",
    "#-Concatonate the slices along the readout dimension, so that we can perform readout undersampling to model sms\n",
    "slicesCoils = slicesShiftedCoils[:,0,:,:]\n",
    "coils       = shiftedCoils[:,0,:,:]\n",
    "\n",
    "for ss in range(1,numslices):\n",
    "    slicesCoils = np.concatenate((slicesCoils,slicesShiftedCoils[:,ss,:,:]),axis = -2)\n",
    "    coils       = np.concatenate((coils,shiftedCoils[:,ss,:,:]),axis = -2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating undersampling mask and kspace which undersampls readout dimension (to models sms) and undersamples phase-encode for in-plance acceleration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Generate the undersampling mask\n",
    "mask = np.zeros(slicesCoils.shape)\n",
    "mask[:,::numslices,::Ry] = 1\n",
    "\n",
    "#-Generate the noise\n",
    "noise = np.random.normal(0,1/snr,mask.shape) + 1j*np.random.normal(0,1/snr,mask.shape)\n",
    "kspace = mask * (sig.fft2c(slicesCoils) + noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating sense operators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def senseForward(x,maps,mask):\n",
    "    return mask * (sig.fft2c(maps*x))\n",
    "def senseAdjoint(x,maps,mask):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp.sum(xp.conj(maps)*(sig.ifft2c(x)),-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the SENSE reconstruction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Compute the adjoint of the kspace data\n",
    "kadj = senseAdjoint(kspace,coils,mask)\n",
    "\n",
    "if(cudaflag):\n",
    "    coils   = cp.asarray(coils)\n",
    "    mask    = cp.asarray(mask)\n",
    "    kadj    = cp.asarray(kadj)\n",
    "    \n",
    "#-Defining the normal operator and performing the reconstruction\n",
    "normal = lambda x: senseAdjoint(senseForward(x.reshape(M*numslices,N),coils,mask),\\\n",
    "                                          coils,mask).ravel()\n",
    "\n",
    "print('SENSE reconstruction ...',end='')\n",
    "smsSense = cp.asnumpy(iterative.conjgrad(normal,kadj.ravel(),kadj.ravel(),\\\n",
    "                                         ite = 20)).reshape(M*numslices,N)\n",
    "print(' Done.')\n",
    "\n",
    "coils = cp.asnumpy(coils)\n",
    "mask  = cp.asnumpy(mask)\n",
    "kadj  = cp.asnumpy(kadj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare SENSE and ground truth "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = np.squeeze(performshift(np.expand_dims(np.reshape(np.sum(np.conj(coils) * slicesCoils,-3),\\\n",
    "                                                          (numslices,M,N)),axis=0),shifts,-1))\n",
    "\n",
    "sense = np.squeeze(performshift(np.expand_dims(np.reshape(smsSense,(numslices,M,N)),axis=0),shifts,-1))\n",
    "\n",
    "display = sig.nor(np.concatenate((truth,sense),axis = 0))\n",
    "sig.mosaic(display,2,numslices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing sense kspace and acs kspace for SPARK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceSense = senseForward(smsSense,coils,1)\n",
    "kspaceAcs   = sig.fft2c(slicesCoils)\n",
    "\n",
    "acsregionX = np.arange((M*numslices)//2 - acsx // 2,(M*numslices)//2 + acsx//2) \n",
    "acsregionY = np.arange(N//2 - acsy // 2,N//2 + acsy//2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining SPARK helper functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reformattingKspaceForSpark(inputKspace,kspaceOriginal,acsregionX,acsregionY,acsx,acsy,normalizationflag):\n",
    "    #Calling things kspaceGrappa are remnants of old code.  Here, kspace grappa can be the reconstructed space\n",
    "    #of whatever reconstruction technique we chose to use\n",
    "    [E,C,_,_] = inputKspace.shape\n",
    "    kspaceAcsCrop     = kspaceOriginal[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] \n",
    "    #Ground truth measured ACS data, will be used as the ground truth to compute kspace error we want learn\n",
    "    kspaceAcsGrappa   = inputKspace[:,:,acsregionX[0]:acsregionX[acsx-1]+1,acsregionY[0]:acsregionY[acsy-1]+1] \n",
    "    #GRAPPA reconstructed ACS region.  kspaceAcsCrop - kspaceAcsGrappa = d will be the supervised error we try to learn\n",
    "    kspaceAcsDifference = kspaceAcsCrop - kspaceAcsGrappa\n",
    "\n",
    "    #Splitting the difference into the real and imaginary part for the network\n",
    "    acs_difference_real = np.real(kspaceAcsDifference)\n",
    "    acs_difference_imag = np.imag(kspaceAcsDifference)\n",
    "\n",
    "\n",
    "    #Adding the batch dimension\n",
    "    kspace_grappa = np.copy(inputKspace)\n",
    "    kspace_grappa_real  = np.real(kspace_grappa)\n",
    "    kspace_grappa_imag  = np.imag(kspace_grappa)\n",
    "    kspace_grappa_split = np.concatenate((kspace_grappa_real, kspace_grappa_imag), axis=1)\n",
    "\n",
    "    #Let's do some normalization\n",
    "    chan_scale_factors_real = np.zeros((E,C),dtype = 'float')\n",
    "    chan_scale_factors_imag = np.zeros((E,C),dtype = 'float')\n",
    "\n",
    "    for e in range(E):\n",
    "        if(normalizationflag):\n",
    "            scale_factor_input = 1/np.amax(np.abs(kspace_grappa_split[e,:,:,:]))\n",
    "            kspace_grappa_split[e,:,:,:] *= scale_factor_input\n",
    "\n",
    "        for c in range(C):\n",
    "            if(normalizationflag):\n",
    "                scale_factor_real = 1/np.amax(np.abs(acs_difference_real[e,c,:,:]))\n",
    "                scale_factor_imag = 1/np.amax(np.abs(acs_difference_imag[e,c,:,:]))\n",
    "            else:\n",
    "                scale_factor_real = 1\n",
    "                scale_factor_imag = 1\n",
    "\n",
    "            chan_scale_factors_real[e,c] = scale_factor_real\n",
    "            chan_scale_factors_imag[e,c] = scale_factor_imag\n",
    "\n",
    "            acs_difference_real[e,c,:,:] *= scale_factor_real\n",
    "            acs_difference_imag[e,c,:,:] *= scale_factor_imag\n",
    "\n",
    "    acs_difference_real = np.expand_dims(acs_difference_real, axis=2)\n",
    "    acs_difference_real = np.expand_dims(acs_difference_real, axis=2)\n",
    "    acs_difference_imag = np.expand_dims(acs_difference_imag, axis=2)\n",
    "    acs_difference_imag = np.expand_dims(acs_difference_imag, axis=2)\n",
    "\n",
    "    #print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "    #print('acs_difference_imag shape: ' + str(acs_difference_imag.shape))\n",
    "\n",
    "    kspace_grappa_split = torch.from_numpy(kspace_grappa_split)\n",
    "    kspace_grappa_split = kspace_grappa_split.to(device, dtype=torch.float)\n",
    "    print('kspace_grappa_split shape: ' + str(kspace_grappa_split.shape))\n",
    "\n",
    "    acs_difference_real = torch.from_numpy(acs_difference_real)\n",
    "    acs_difference_real = acs_difference_real.to(device, dtype=torch.float)\n",
    "    print('acs_difference_real shape: ' + str(acs_difference_real.shape))\n",
    "\n",
    "    acs_difference_imag = torch.from_numpy(acs_difference_imag)\n",
    "    acs_difference_imag = acs_difference_imag.to(device, dtype=torch.float)\n",
    "    print('acs_target_imag shape: ' + str(acs_difference_imag.shape))\n",
    "    \n",
    "    return kspace_grappa_split, acs_difference_real, acs_difference_imag, chan_scale_factors_real, chan_scale_factors_imag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainingSparkNetwork(kspaceGrappaSplit,acsDifferenceReal,acsDifferenceImag,acsx,acsy,learningRate,iterations):\n",
    "    '''\n",
    "    Trains a SPARK networks given some appropriately formatted grappa kspace, acsDifferenceReal, and acsDifferenceImaginary\n",
    "    Inputs:\n",
    "        kspaceGrappaSplit: allContrasts x 2 * allChannels x M x N,             Grappa reconstructed kspace which will \n",
    "                                                                               be used to learn error\n",
    "        acsDifferenceReal: allContrasts x allChaannels x 1 x 1 x M x N,        Difference between measured and GRAPPA\n",
    "                                                                               ACS real portion\n",
    "        acsDifferenceImag: allContrasts x allChaannels x 1 x 1 M x N,          Difference between measured and GRAPPA\n",
    "                                                                               ACS imag portion             \n",
    "        acs:               acss x 1,                                           Indices of ACS region\n",
    "        learningRate:      scalar,                                             Learaning rate for the networks\n",
    "        iterations:        scalar,                                             Number of iterations we want to train\n",
    "    Outputs:\n",
    "        A network which should reconstruct each contrast and channel        \n",
    "    '''\n",
    "    \n",
    "    [E,C,_,_,_,_] = acsDifferenceReal.shape\n",
    "\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #Training the real models\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    real_models      = {}\n",
    "    real_model_names = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for e in range(0,E):\n",
    "        for c in range(0,C):\n",
    "            model_name = 'model' + 'E' + str(e) + 'C' + str(c) + 'r'\n",
    "            model = models.SPARK_Netv2(coils = C,kernelsize = 3,acsx = acsx, acsy = acsy)\n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            kspsplit = torch.unsqueeze(kspaceGrappaSplit[e,:,:,:],axis = 0)\n",
    "            \n",
    "            print('Training {}'.format(model_name))\n",
    "            \n",
    "            optimizer = optim.Adam(model.parameters(),lr=learningRate)\n",
    "            running_loss = 0\n",
    "            \n",
    "            for epoch in range(iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                _,loss_out = model(kspsplit)\n",
    "                loss = criterion(loss_out,acsDifferenceReal[e,c,:,:,:,:])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss = loss.item()\n",
    "                if(epoch == 0):\n",
    "                    print('Initial Loss: %.10f' % (running_loss))\n",
    "            \n",
    "            real_model_names.append(model_name)\n",
    "            real_models.update({model_name:model})\n",
    "            print('Final Loss:   %.10f' % (running_loss))\n",
    "    \n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    #Training the imaginary model\n",
    "    #~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
    "    imag_models      = {}\n",
    "    imag_model_names = []\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    for e in range(0,E):\n",
    "        for c in range(0,C):\n",
    "            model_name = 'model' + 'E' + str(e) + 'C' + str(c) + 'i'            \n",
    "            model = models.SPARK_Netv2(coils = C,kernelsize = 3,acsx = acsx, acsy = acsy)\n",
    "            \n",
    "            model.to(device)\n",
    "            \n",
    "            kspsplit = torch.unsqueeze(kspaceGrappaSplit[e,:,:,:],axis = 0)\n",
    "            \n",
    "            print('Training {}'.format(model_name))\n",
    "            \n",
    "            optimizer    = optim.Adam(model.parameters(),lr = learningRate)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for epoch in range(iterations):\n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                _,loss_out = model(kspsplit)\n",
    "                loss = criterion(loss_out,acsDifferenceImag[e,c,:,:,:,:])\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                running_loss = loss.item()\n",
    "                if(epoch == 0):\n",
    "                        print('Initial Loss: %.10f' % (running_loss))\n",
    "                        \n",
    "            imag_model_names.append(model_name)\n",
    "            imag_models.update({model_name : model})\n",
    "\n",
    "            print('Final Loss:   %.10f' % (running_loss))\n",
    "\n",
    "    return real_models,real_model_names,imag_models,imag_model_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,chanScaleFactorReal,chanScaleFactorImag):\n",
    "    '''\n",
    "    Given a set of models trained for a particular contrast, apply SPARK to all of the contrasts\n",
    "    Inputs:\n",
    "        kspaceToCorrect   - M x N,       Kspace that we want to correct\n",
    "        kspaceGrappasplit - allcoils x M x N  Kspace that will be used to reconstuct the particular for this kspace\n",
    "        real_model      - model          Model for correcting the real component\n",
    "        imag_model      - model          Model for correcting the imaginary component\n",
    "        chanScaleFactor - Scalar         Scaling parameter for the particular piece of kspace which is corrected\n",
    "    outputs:\n",
    "        kspaceCorrected - M x N       Corrected kspace\n",
    "        \n",
    "    '''\n",
    "    \n",
    "    correctionr = real_model(torch.unsqueeze(kspaceGrappaSplit,axis=0))[0].cpu().detach().numpy()\n",
    "    correctioni = imag_model(torch.unsqueeze(kspaceGrappaSplit,axis=0))[0].cpu().detach().numpy()\n",
    "    corrected = correctionr[0,0,:,:]/chanScaleFactorReal + 1j * correctioni[0,0,:,:] / chanScaleFactorImag + kspaceToCorrect\n",
    "    \n",
    "    return corrected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform SPARK training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "kspaceSense = np.expand_dims(np.squeeze(kspaceSense),axis = 0)\n",
    "kspaceAcs   = np.expand_dims(np.squeeze(kspaceAcs),axis = 0)\n",
    "#Reformatting the data\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceSense,kspaceAcs,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n",
    "\n",
    "realSparkGrappaModels,realSparkGrappaNames,imagSparkGrappaModels,imagSparkGrappaNames = \\\n",
    "    trainingSparkNetwork(kspace_grappa_split,acs_difference_real,acs_difference_imag,acsregionX,acsregionY,learningRate,sparkIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform correction and ACS replacement "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#will use each model contrast to reconstruct each recon contrast\n",
    "kspaceCorrected    = np.zeros((C,M*numslices,N),dtype = complex)\n",
    "\n",
    "for c in range(0,C):\n",
    "    #Perform reconstruction coil by coil\n",
    "    model_namer = 'model' + 'E' + str(0) + 'C' + str(c) + 'r'\n",
    "    model_namei = 'model' + 'E' + str(0) + 'C' + str(c) + 'i'\n",
    "\n",
    "    real_model = realSparkGrappaModels[model_namer]\n",
    "    imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "    kspaceToCorrect   = kspaceSense[0,c,:,:]\n",
    "    kspaceGrappaSplit = kspace_grappa_split[0,:,:,:]\n",
    "\n",
    "    currentCorrected = \\\n",
    "            applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                chan_scale_factors_real[0,c], chan_scale_factors_imag[0,c])\n",
    "\n",
    "    kspaceCorrected[c,:,:] = currentCorrected       \n",
    "            \n",
    "#ACS replaced\n",
    "kspaceCorrectedReplaced    = np.copy(kspaceCorrected)\n",
    "\n",
    "\n",
    "kspaceCorrectedReplaced[:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] = \\\n",
    "    kspaceAcs[0,:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing sense image from corrected kspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Perform IFFT and coil combine\n",
    "spark = np.sum(np.conj(coils) * sig.ifft2c(kspaceCorrectedReplaced),-3)\n",
    "spark = np.squeeze(performshift(np.expand_dims(np.reshape(spark,(numslices,M,N)),axis=0),shifts,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare truth, sense, and spark "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = sig.nor(np.concatenate((truth,sense,spark),axis = 0))\n",
    "sig.mosaic(display,3,numslices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining wave encoding parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slicethickness = 1e-3 #[m]\n",
    "\n",
    "os       = 3\n",
    "cycles   = 2\n",
    "Gymax    = 16 * 1e-3\n",
    "Gzmax    = 16 * 1e-3     #[T/m]\n",
    "Tadc     = 1432.7*1e-6   #[s]\n",
    "gamma    = 42.577*1e6    #[Hz/T]\n",
    "FOVy     = N * 1e-3      #[m]\n",
    "FOVz     = (numslices+1) * slicedistance * slicethickness\n",
    "\n",
    "Nro      = M * os\n",
    "yind     = np.linspace(-FOVy/2,FOVy/2,N)           #[m]\n",
    "zind     = np.linspace(-FOVz/2,FOVz/2,numslices)   #[m]\n",
    "adc      = np.linspace(0,Tadc,Nro)                 #[s]\n",
    "\n",
    "#-Generating the point spread functions\n",
    "gradienty = np.sin(cycles * np.pi * adc / Tadc);\n",
    "gradientz = np.cos(cycles * np.pi * adc / Tadc);\n",
    "\n",
    "psf = np.zeros((1,numslices,Nro,N),dtype = complex)\n",
    "\n",
    "for yy in range(0,N):\n",
    "    for ss in range(0,numslices):\n",
    "        psf[0,ss,:,yy] = np.exp(1j * gamma * Tadc * (Gymax * gradienty * yind[yy] + Gzmax * gradientz * zind[ss]))\n",
    "\n",
    "\n",
    "#-Shift the psf and restructure to match readout oversampled dimensions\n",
    "psfShifted = performshift(psf,shifts)\n",
    "\n",
    "psfRo       = psfShifted[:,0,:,:]\n",
    "\n",
    "for ss in range(1,numslices):\n",
    "    psfRo = np.concatenate((psfRo,psfShifted[:,ss,:,:]),axis = -2)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining wave encoding operators "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padreadout = (Nro - M)//2\n",
    "\n",
    "def sforwave(x,coils):\n",
    "    return coils * x\n",
    "\n",
    "def sadjwave(x,coils):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp.sum(xp.conj(coils)*x,-3)\n",
    "\n",
    "Fx    = lambda x: sig.fft(x,ax = -2)    #Perform fft in the readout direction\n",
    "Fy    = lambda x: sig.fft(x,ax = -1)    #Perform fft in the phaseencode direction\n",
    "Fxadj = lambda x: sig.ifft(x,ax = -2)   #Perform ifft in the readout direction\n",
    "Fyadj = lambda x: sig.ifft(x,ax = -1)   #Perform ifft in the phaseencode direction\n",
    "\n",
    "def waveForward(x,psf): #Perform the forward wave operation through psf modeling\n",
    "    return psf * x\n",
    "\n",
    "def waveAdjoint(x,psf): #Perform the adjoint wave operation through psf modeling\n",
    "    xp = cp.get_array_module(x)\n",
    "    return xp.conj(psf) * x \n",
    "\n",
    "def resize(x,padreadout,inpdims):\n",
    "    xp = cp.get_array_module(x)\n",
    "    \n",
    "    if(inpdims == 3):\n",
    "        return xp.pad(x,((0,0),(padreadout,padreadout),(0,0)),mode = 'constant',constant_values = 0)\n",
    "    elif(inpdims == 4):\n",
    "        return xp.pad(x,((0,0),(0,0),(padreadout,padreadout),(0,0)),mode = 'constant',constant_values = 0)\n",
    "    \n",
    "crop = lambda x: x[:,:,Nro//2 - M//2:Nro//2 + M//2,:]\n",
    "\n",
    "def senseWaveForward(x,maps,psf,padreadout,mask):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return mask*Fy(waveForward(Fx(xp.reshape(resize(xp.reshape(sforwave(x,maps),\\\n",
    "        (C,numslices,M,N)),padreadout,inpdims = 4),(C,numslices*Nro,N))),psf))\n",
    "\n",
    "def senseWaveAdjoint(x,maps,psf,mask):\n",
    "    xp = cp.get_array_module(x)\n",
    "    return sadjwave(xp.reshape(crop(np.reshape(Fxadj(waveAdjoint(Fyadj(xp.conj(mask) * x),psf)),\\\n",
    "                                               (C,numslices,Nro,N))),(C,numslices*M,N)),maps)\n",
    "\n",
    "def analyzePsf(x,psf,padreadout):\n",
    "    \n",
    "    tmp = np.reshape(x,(numslices,M,N))\n",
    "    tmp = resize(tmp,padreadout,inpdims = 3)\n",
    "    tmp = np.reshape(tmp,(1,numslices*Nro,N))\n",
    "    \n",
    "    return Fxadj(psf*Fx(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating wave encoded kspace "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Generate the undersampling mask\n",
    "maskWave = np.zeros((C,M*os*numslices,N))\n",
    "maskWave[:,::numslices,::Ry] = 1\n",
    "\n",
    "#-Generate the noise\n",
    "noiseWave = np.random.normal(0,1/snr,maskWave.shape) + 1j*np.random.normal(0,1/snr,maskWave.shape)\n",
    "kspaceWave = maskWave*(Fy(waveForward(Fx(np.reshape(resize(np.reshape(slicesCoils,(C,numslices,M,N)),\\\n",
    "                    padreadout,inpdims = 4),(C,numslices*Nro,N))),psfRo)) + noiseWave)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing wave-encoded reconstruction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-Compute the adjoint of the kspace data\n",
    "kadjWave = senseWaveAdjoint(kspaceWave,coils,psfRo,maskWave)\n",
    "\n",
    "if(cudaflag):\n",
    "    coils       = cp.asarray(coils)\n",
    "    maskWave    = cp.asarray(maskWave)\n",
    "    kadjWave    = cp.asarray(kadjWave)\n",
    "    psfRo       = cp.asarray(psfRo)\n",
    "    \n",
    "#-Defining the normal operator and performing the reconstruction\n",
    "normalWave = lambda x: senseWaveAdjoint(senseWaveForward(x.reshape(M*numslices,N),coils,psfRo,padreadout,maskWave),\\\n",
    "                                          coils,psfRo,maskWave).ravel()\n",
    "\n",
    "print('WAVE SENSE reconstruction ...',end='')\n",
    "smsWave = cp.asnumpy(iterative.conjgrad(normalWave,kadjWave.ravel(),kadjWave.ravel(),\\\n",
    "                                         ite = 20)).reshape(M*numslices,N)\n",
    "print(' Done.')\n",
    "\n",
    "coils    = cp.asnumpy(coils)\n",
    "maskWave = cp.asnumpy(maskWave)\n",
    "kadjWave = cp.asnumpy(kadjWave)\n",
    "psfRo    = cp.asnumpy(psfRo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing ground truth, sense, wave "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave =  np.squeeze(performshift(np.expand_dims(np.reshape(smsWave,(numslices,M,N)),axis=0),shifts,-1))\n",
    "\n",
    "display = sig.nor(np.concatenate((truth,sense,wave),axis = 0))\n",
    "sig.mosaic(display,3,numslices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sense Total rmse:   %.2f' % (sig.rmse(truth,sense)*100) )\n",
    "print('Wave  Total rmse:   %.2f' % (sig.rmse(truth,wave)*100) )\n",
    "\n",
    "for ss in range(0,numslices):\n",
    "    print('Slice %d:' %(ss+1))\n",
    "    print('  sense rmse: %.2f' % (sig.rmse(truth[ss,:,:],sense[ss,:,:])*100))\n",
    "    print('  wave  rmse: %.2f' % (sig.rmse(truth[ss,:,:],wave[ss,:,:])*100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up kspaces for wave-encoded SPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kspaceWaveSpark = np.expand_dims(senseWaveForward(smsWave,coils,psfRo,padreadout,mask = 1),axis = 0)\n",
    "kspaceWaveAcs   = np.expand_dims(Fy(waveForward(Fx(np.reshape(resize(np.reshape(slicesCoils,(C,numslices,M,N)),\\\n",
    "                    padreadout,inpdims = 4),(C,numslices*Nro,N))),psfRo)),axis = 0)\n",
    "\n",
    "#-Adjust the acs region to be the oversampled size in wave\n",
    "acsregionX = np.arange(0,M * numslices * os)\n",
    "acsx = len(acsregionX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing wave-encoded SPARK reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Reformatting the data\n",
    "[kspace_grappa_split, acs_difference_real, acs_difference_imag,chan_scale_factors_real,chan_scale_factors_imag] = \\\n",
    "    reformattingKspaceForSpark(kspaceWaveSpark,kspaceWaveAcs,acsregionX,acsregionY,acsx,acsy,normalizationflag)\n",
    "\n",
    "realSparkGrappaModels,realSparkGrappaNames,imagSparkGrappaModels,imagSparkGrappaNames = \\\n",
    "    trainingSparkNetwork(kspace_grappa_split,acs_difference_real,acs_difference_imag,acsregionX,acsregionY,learningRate,sparkIterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing the correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#will use each model contrast to reconstruct each recon contrast\n",
    "kspaceCorrectedWave    = np.zeros((C,M*numslices*os,N),dtype = complex)\n",
    "\n",
    "for c in range(0,C):\n",
    "    #Perform reconstruction coil by coil\n",
    "    model_namer = 'model' + 'E' + str(0) + 'C' + str(c) + 'r'\n",
    "    model_namei = 'model' + 'E' + str(0) + 'C' + str(c) + 'i'\n",
    "\n",
    "    real_model = realSparkGrappaModels[model_namer]\n",
    "    imag_model = imagSparkGrappaModels[model_namei]\n",
    "\n",
    "    kspaceToCorrect   = kspaceWaveSpark[0,c,:,:]\n",
    "    kspaceGrappaSplit = kspace_grappa_split[0,:,:,:]\n",
    "\n",
    "    currentCorrected = \\\n",
    "            applySparkCorrection(kspaceToCorrect,kspaceGrappaSplit,real_model,imag_model,\\\n",
    "                chan_scale_factors_real[0,c], chan_scale_factors_imag[0,c])\n",
    "\n",
    "    kspaceCorrectedWave[c,:,:] = currentCorrected       \n",
    "            \n",
    "#ACS replaced\n",
    "kspaceCorrectedReplacedWave   = np.copy(kspaceCorrectedWave)\n",
    "\n",
    "\n",
    "kspaceCorrectedReplacedWave[:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] = \\\n",
    "    kspaceWaveAcs[0,:,acsregionX[0]:acsregionX[acsx-1],acsregionY[0]:acsregionY[acsy-1]] \n",
    "    \n",
    "#Perform IFFT and coil combine\n",
    "sparkWave = senseWaveAdjoint(kspaceCorrectedReplacedWave,coils,psfRo,mask = 1)\n",
    "sparkWave = np.squeeze(performshift(np.expand_dims(np.reshape(sparkWave,(numslices,M,N)),axis=0),shifts,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display = sig.nor(np.concatenate((truth,wave,sparkWave),axis = 0))\n",
    "sig.mosaic(display,3,numslices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {'truth': np.squeeze(truth),\n",
    "           'sense': np.squeeze(sense),\n",
    "           'spark': np.squeeze(spark),\n",
    "           'wave':  np.squeeze(wave),\n",
    "           'sparkwave': np.squeeze(sparkWave),\n",
    "           'mbfactor': numslices,\n",
    "           'Ry': Ry,\n",
    "           'acsy': acsy,           \n",
    "           'Iterations': sparkIterations,\n",
    "           'learningRate': learningRate,\n",
    "           'snr' : snr,\n",
    "           'slices':  slices,\n",
    "           'slicedistance': slicedistance,\n",
    "           'os' : os,\n",
    "            'cycles' : cycles,\n",
    "          'Gymax' :Gymax,\n",
    "          'Gzmax' :Gzmax,\n",
    "          'Tadc':Tadc,\n",
    "          'FOVy':FOVy,\n",
    "          'FOVz':FOVz,\n",
    "          'fovshift':fovshift}\n",
    "\n",
    "sp.io.savemat('figure4results.mat', results, oned_as='row')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
